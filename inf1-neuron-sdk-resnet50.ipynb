{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Inferentia inference on Amazon EC2 Inf1 instance\n",
    "This example demonstrates AWS Inferentia inference with TensorFlow and AWS Neuron SDK compiler and runtime\n",
    "\n",
    "This example was tested on Amazon EC2 `inf1.xlarge` the following AWS Deep Learning AMI: \n",
    "`Deep Learning AMI (Ubuntu 18.04) Version 35.0`\n",
    "\n",
    "Run this notebook using the following conda environment:\n",
    "`aws_neuron_tensorflow_p36`\n",
    "\n",
    "Prepare your imagenet validation TFRecord files using the following helper script:\n",
    "https://github.com/tensorflow/models/blob/archive/research/inception/inception/data/download_and_preprocess_imagenet.sh\n",
    "\n",
    "Save it to `/home/ubuntu/datasets/` or update the dataset location in the `get_dataset()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/aws/neuron/bin/neuron-cli reset\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.neuron as tfn\n",
    "import tensorflow.compat.v1.keras as keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from concurrent import futures\n",
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/tensorflow/tensorflow/issues/29931\n",
    "temp = tf.zeros([8, 224, 224, 3])\n",
    "_ = tf.keras.applications.resnet50.preprocess_input(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50 FP32 saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102973440/102967424 [==============================] - 1s 0us/step\n",
      "WARNING:tensorflow:From <ipython-input-4-cc6f128953d9>:10: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_saved_model/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "# Export SavedModel\n",
    "saved_model_dir = 'resnet50_saved_model'\n",
    "shutil.rmtree(saved_model_dir, ignore_errors=True)\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "model = ResNet50(weights='imagenet')\n",
    "tf.saved_model.simple_save(session = keras.backend.get_session(),\n",
    "                           export_dir = saved_model_dir,\n",
    "                           inputs = {'input_1:0': model.inputs[0]},\n",
    "                           outputs = {'probs/Softmax:0': model.outputs[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile models with different batch sizes and cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_inf1_model(saved_model_dir, inf1_model_dir, batch_size=1, num_cores=1, use_static_weights=False):\n",
    "    print(f'-----------batch size: {batch_size}, num cores: {num_cores}----------')\n",
    "    print('Compiling...')\n",
    "    \n",
    "    compiled_model_dir = f'resnet50_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "    inf1_compiled_model_dir = os.path.join(inf1_model_dir, compiled_model_dir)\n",
    "    shutil.rmtree(inf1_compiled_model_dir, ignore_errors=True)\n",
    "\n",
    "    example_input = np.zeros([batch_size,224,224,3], dtype='float32')\n",
    "\n",
    "    compiler_args = ['--verbose','1', '--num-neuroncores', str(num_cores)]\n",
    "    if use_static_weights:\n",
    "        compiler_args.append('--static-weights')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    compiled_res = tfn.saved_model.compile(model_dir = saved_model_dir,\n",
    "                            model_feed_dict={'input_1:0': example_input},\n",
    "                            new_model_dir = inf1_compiled_model_dir,\n",
    "                            dynamic_batch_size=True,\n",
    "                            compiler_workdir=f'./compiler-workdir/{inf1_compiled_model_dir}',\n",
    "                            compiler_args = compiler_args)\n",
    "    print(f'Compile time: {time.time() - start_time}')\n",
    "    \n",
    "    compile_success = False\n",
    "    perc_on_inf = compiled_res['OnNeuronRatio'] * 100\n",
    "    if perc_on_inf > 50:\n",
    "        compile_success = True\n",
    "            \n",
    "    print(inf1_compiled_model_dir)\n",
    "    print(compiled_res)\n",
    "    print('----------- Done! ----------- \\n')\n",
    "    \n",
    "    return compile_success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `tf.data` to read ImageNet validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_image_record(record):\n",
    "    feature_map = {'image/encoded': tf.io.FixedLenFeature([], tf.string, ''),\n",
    "                  'image/class/label': tf.io.FixedLenFeature([1], tf.int64, -1),\n",
    "                  'image/class/text': tf.io.FixedLenFeature([], tf.string, '')}\n",
    "    obj = tf.io.parse_single_example(serialized=record, features=feature_map)\n",
    "    imgdata = obj['image/encoded']\n",
    "    label = tf.cast(obj['image/class/label'], tf.int32)   \n",
    "    label_text = tf.cast(obj['image/class/text'], tf.string)   \n",
    "    return imgdata, label, label_text\n",
    "\n",
    "def val_preprocessing(record):\n",
    "    imgdata, label, label_text = deserialize_image_record(record)\n",
    "    label -= 1\n",
    "    image = tf.io.decode_jpeg(imgdata, channels=3, \n",
    "                              fancy_upscaling=False, \n",
    "                              dct_method='INTEGER_FAST')\n",
    "\n",
    "    shape = tf.shape(image)\n",
    "    height = tf.cast(shape[0], tf.float32)\n",
    "    width = tf.cast(shape[1], tf.float32)\n",
    "    side = tf.cast(tf.convert_to_tensor(256, dtype=tf.int32), tf.float32)\n",
    "\n",
    "    scale = tf.cond(tf.greater(height, width),\n",
    "                  lambda: side / width,\n",
    "                  lambda: side / height)\n",
    "    \n",
    "    new_height = tf.cast(tf.math.rint(height * scale), tf.int32)\n",
    "    new_width = tf.cast(tf.math.rint(width * scale), tf.int32)\n",
    "    \n",
    "    image = tf.image.resize(image, [new_height, new_width], method='bicubic')\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 224, 224)\n",
    "    \n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    \n",
    "    return image, label, label_text\n",
    "\n",
    "def get_dataset(batch_size, use_cache=False):\n",
    "    data_dir = '/home/ubuntu/datasets/*'\n",
    "    files = tf.io.gfile.glob(os.path.join(data_dir))\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    \n",
    "    dataset = dataset.map(map_func=val_preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat(count=1)\n",
    "    \n",
    "    if use_cache:\n",
    "        shutil.rmtree('tfdatacache', ignore_errors=True)\n",
    "        os.mkdir('tfdatacache')\n",
    "        dataset = dataset.cache(f'./tfdatacache/imagenet_val')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single AWS Inferentia chip execution\n",
    "* Single core compiled models with automatic data parallel model upto 4 cores\n",
    "* Multi-core compiled models for pipeline execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def inf1_predict_benchmark_single_threaded(neuron_saved_model_name, batch_size, user_batch_size, num_cores, use_cache=False, warm_up=10):\n",
    "    print(f'Running model {neuron_saved_model_name}, user_batch_size: {user_batch_size}\\n')\n",
    "\n",
    "    model_inf1 = tf.contrib.predictor.from_saved_model(neuron_saved_model_name)\n",
    "\n",
    "    iter_times = []\n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    display_threshold = 0\n",
    "    warm_up = 10\n",
    "\n",
    "    ds = get_dataset(user_batch_size, use_cache)\n",
    "\n",
    "    ds_iter = ds.make_initializable_iterator()\n",
    "    ds_next = ds_iter.get_next()\n",
    "    ds_init_op = ds_iter.initializer\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        if use_cache:\n",
    "            sess.run(ds_init_op)\n",
    "            print('\\nCaching dataset ...')\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                while True:\n",
    "                    (validation_ds,label,_) = sess.run(ds_next)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                pass\n",
    "            print(f'Caching finished: {time.time()-start_time} sec')  \n",
    "\n",
    "        try:\n",
    "            sess.run(ds_init_op)\n",
    "            counter = 0\n",
    "            \n",
    "            total_datas = 1000\n",
    "            display_every = 100\n",
    "            display_threshold = display_every\n",
    "            \n",
    "            ipname = list(model_inf1.feed_tensors.keys())[0]\n",
    "            resname = list(model_inf1.fetch_tensors.keys())[0]\n",
    "            \n",
    "            walltime_start = time.time()\n",
    "\n",
    "            while True:\n",
    "                (validation_ds,batch_labels,_) = sess.run(ds_next)\n",
    "\n",
    "                model_feed_dict={ipname: validation_ds}\n",
    "\n",
    "                if counter == 0:\n",
    "                    for i in range(warm_up):\n",
    "                        _ = model_inf1(model_feed_dict);                    \n",
    "\n",
    "                start_time = time.time()\n",
    "                inf1_results = model_inf1(model_feed_dict);\n",
    "                iter_times.append(time.time() - start_time)\n",
    "                \n",
    "                actual_labels.extend(label for label_list in batch_labels for label in label_list)\n",
    "                pred_labels.extend(list(np.argmax(inf1_results[resname], axis=1)))\n",
    "\n",
    "                if counter*user_batch_size >= display_threshold:\n",
    "                    print(f'Images {counter*user_batch_size}/{total_datas}. Average i/s {np.mean(user_batch_size/np.array(iter_times[-display_every:]))}')\n",
    "                    display_threshold+=display_every\n",
    "\n",
    "                counter+=1\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "    acc_inf1 = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)\n",
    "    iter_times = np.array(iter_times)\n",
    "    \n",
    "    instacne_ip = '35.82.33.15'\n",
    "    \n",
    "    results = pd.DataFrame(columns = [f'inf1_compiled_batch_size_{batch_size}_compiled_cores_{num_cores}'])\n",
    "    results.loc['instance_type']           = [requests.get(f'http://{instance_ip}/latest/meta-data/instance-type').text]\n",
    "    results.loc['compiled_batch_size']     = [batch_size]\n",
    "    results.loc['user_batch_size']         = [user_batch_size]\n",
    "    results.loc['accuracy']                = [acc_inf1]\n",
    "    results.loc['prediction_time']         = [np.sum(iter_times)]\n",
    "    results.loc['wall_time']               = [time.time() - walltime_start]\n",
    "    results.loc['images_per_sec_mean']     = [np.mean(user_batch_size / iter_times)]\n",
    "    results.loc['images_per_sec_std']      = [np.std(user_batch_size / iter_times, ddof=1)]\n",
    "    results.loc['latency_mean']            = [np.mean(iter_times) * 1000]\n",
    "    results.loc['latency_99th_percentile'] = [np.percentile(iter_times, q=99, interpolation=\"lower\") * 1000]\n",
    "    results.loc['latency_median']          = [np.median(iter_times) * 1000]\n",
    "    results.loc['latency_min']             = [np.min(iter_times) * 1000]\n",
    "    display(results.T)\n",
    "\n",
    "    return results, iter_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size:  1 compile start\n",
      "-----------batch size: 1, num cores: 1----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph {subgraph neuron_op_d6f098c01c780733 with input tensors [\"<tf.Tensor 'input_10/_0:0' shape=(1, 224, 224, 3) dtype=float32>\"], output tensors [\"<tf.Tensor 'probs/Softmax:0' shape=(1, 1000) dtype=float32>\"]} with neuron-cc; you may check progress by inspecting file /home/ubuntu/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4647\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 876\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 874\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_1/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_1\n",
      "Compile time: 93.93772840499878\n",
      "resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_1\n",
      "{'OnNeuronRatio': 0.997716894977169}\n",
      "----------- Done! ----------- \n",
      "\n",
      "batch size:  2 compile start\n",
      "-----------batch size: 2, num cores: 1----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph {subgraph neuron_op_d6f098c01c780733 with input tensors [\"<tf.Tensor 'input_10/_0:0' shape=(2, 224, 224, 3) dtype=float32>\"], output tensors [\"<tf.Tensor 'probs/Softmax:0' shape=(2, 1000) dtype=float32>\"]} with neuron-cc; you may check progress by inspecting file /home/ubuntu/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4647\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 876\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 874\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_1/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_1\n",
      "Compile time: 82.65045809745789\n",
      "resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_1\n",
      "{'OnNeuronRatio': 0.997716894977169}\n",
      "----------- Done! ----------- \n",
      "\n",
      "batch size:  4 compile start\n",
      "-----------batch size: 4, num cores: 1----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph {subgraph neuron_op_d6f098c01c780733 with input tensors [\"<tf.Tensor 'input_10/_0:0' shape=(4, 224, 224, 3) dtype=float32>\"], output tensors [\"<tf.Tensor 'probs/Softmax:0' shape=(4, 1000) dtype=float32>\"]} with neuron-cc; you may check progress by inspecting file /home/ubuntu/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4647\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 876\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 874\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_1/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_1\n",
      "Compile time: 89.35167336463928\n",
      "resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_1\n",
      "{'OnNeuronRatio': 0.997716894977169}\n",
      "----------- Done! ----------- \n",
      "\n",
      "batch size:  8 compile start\n",
      "-----------batch size: 8, num cores: 1----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph {subgraph neuron_op_d6f098c01c780733 with input tensors [\"<tf.Tensor 'input_10/_0:0' shape=(8, 224, 224, 3) dtype=float32>\"], output tensors [\"<tf.Tensor 'probs/Softmax:0' shape=(8, 1000) dtype=float32>\"]} with neuron-cc; you may check progress by inspecting file /home/ubuntu/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_8_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4647\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 876\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 874\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_8_inf1_cores_1/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_8_inf1_cores_1\n",
      "Compile time: 118.13438081741333\n",
      "resnet50_inf1_saved_models/resnet50_batch_8_inf1_cores_1\n",
      "{'OnNeuronRatio': 0.997716894977169}\n",
      "----------- Done! ----------- \n",
      "\n",
      "batch size:  16 compile start\n",
      "-----------batch size: 16, num cores: 1----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph {subgraph neuron_op_d6f098c01c780733 with input tensors [\"<tf.Tensor 'input_10/_0:0' shape=(16, 224, 224, 3) dtype=float32>\"], output tensors [\"<tf.Tensor 'probs/Softmax:0' shape=(16, 1000) dtype=float32>\"]} with neuron-cc; you may check progress by inspecting file /home/ubuntu/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_16_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4647\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 876\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 874\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_16_inf1_cores_1/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_16_inf1_cores_1\n",
      "Compile time: 188.770325422287\n",
      "resnet50_inf1_saved_models/resnet50_batch_16_inf1_cores_1\n",
      "{'OnNeuronRatio': 0.997716894977169}\n",
      "----------- Done! ----------- \n",
      "\n",
      "batch size:  32 compile start\n",
      "-----------batch size: 32, num cores: 1----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph {subgraph neuron_op_d6f098c01c780733 with input tensors [\"<tf.Tensor 'input_10/_0:0' shape=(32, 224, 224, 3) dtype=float32>\"], output tensors [\"<tf.Tensor 'probs/Softmax:0' shape=(32, 1000) dtype=float32>\"]} with neuron-cc; you may check progress by inspecting file /home/ubuntu/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_32_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4647\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 876\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 874\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_32_inf1_cores_1/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_32_inf1_cores_1\n",
      "Compile time: 345.7738230228424\n",
      "resnet50_inf1_saved_models/resnet50_batch_32_inf1_cores_1\n",
      "{'OnNeuronRatio': 0.997716894977169}\n",
      "----------- Done! ----------- \n",
      "\n",
      "batch size:  64 compile start\n",
      "-----------batch size: 64, num cores: 1----------\n",
      "Compiling...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph {subgraph neuron_op_d6f098c01c780733 with input tensors [\"<tf.Tensor 'input_10/_0:0' shape=(64, 224, 224, 3) dtype=float32>\"], output tensors [\"<tf.Tensor 'probs/Softmax:0' shape=(64, 1000) dtype=float32>\"]} with neuron-cc; you may check progress by inspecting file /home/ubuntu/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_64_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4647\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 876\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 874\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_64_inf1_cores_1/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_64_inf1_cores_1\n",
      "Compile time: 695.3715460300446\n",
      "resnet50_inf1_saved_models/resnet50_batch_64_inf1_cores_1\n",
      "{'OnNeuronRatio': 0.997716894977169}\n",
      "----------- Done! ----------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inf1_model_dir = 'resnet50_inf1_saved_models'\n",
    "saved_model_dir = 'resnet50_saved_model'\n",
    "\n",
    "\n",
    "# testing batch size\n",
    "batch_list = [1,2,4,8,16,32,64]\n",
    "for batch in batch_list:\n",
    "    print('batch size:', batch, 'compile start')\n",
    "    compile_inf1_model(saved_model_dir, inf1_model_dir, batch_size=batch, num_cores=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_1\n",
      "Running model resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_1, user_batch_size: 10\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "Images 100/1000. Average i/s 491.41810926716494\n",
      "Images 200/1000. Average i/s 460.18351716457835\n",
      "Images 300/1000. Average i/s 460.72387736524547\n",
      "Images 400/1000. Average i/s 461.2004287554968\n",
      "Images 500/1000. Average i/s 464.32750852578755\n",
      "Images 600/1000. Average i/s 460.61919349607024\n",
      "Images 700/1000. Average i/s 460.1897324345884\n",
      "Images 800/1000. Average i/s 465.763023338468\n",
      "Images 900/1000. Average i/s 465.28044390084625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>compiled_batch_size</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf1_compiled_batch_size_1_compiled_cores_1</th>\n",
       "      <td>inf1.xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.919</td>\n",
       "      <td>2.20407</td>\n",
       "      <td>5.14522</td>\n",
       "      <td>464.954</td>\n",
       "      <td>72.2145</td>\n",
       "      <td>22.0407</td>\n",
       "      <td>30.8819</td>\n",
       "      <td>21.4716</td>\n",
       "      <td>15.3298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            instance_type compiled_batch_size  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_1   inf1.xlarge                   1   \n",
       "\n",
       "                                            user_batch_size accuracy  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_1              10    0.919   \n",
       "\n",
       "                                            prediction_time wall_time  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_1         2.20407   5.14522   \n",
       "\n",
       "                                            images_per_sec_mean  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_1             464.954   \n",
       "\n",
       "                                            images_per_sec_std latency_mean  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_1            72.2145      22.0407   \n",
       "\n",
       "                                            latency_99th_percentile  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_1                 30.8819   \n",
       "\n",
       "                                            latency_median latency_min  \n",
       "inf1_compiled_batch_size_1_compiled_cores_1        21.4716     15.3298  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_1\n",
      "Running model resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_1, user_batch_size: 20\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "Images 100/1000. Average i/s 666.7027829732694\n",
      "Images 200/1000. Average i/s 658.0821125166833\n",
      "Images 300/1000. Average i/s 675.1690961212332\n",
      "Images 400/1000. Average i/s 690.5629491987505\n",
      "Images 500/1000. Average i/s 698.9765127805282\n",
      "Images 600/1000. Average i/s 698.7299597525881\n",
      "Images 700/1000. Average i/s 698.7823925386114\n",
      "Images 800/1000. Average i/s 696.8478468738555\n",
      "Images 900/1000. Average i/s 703.8326940938057\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>compiled_batch_size</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf1_compiled_batch_size_2_compiled_cores_1</th>\n",
       "      <td>inf1.xlarge</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.919</td>\n",
       "      <td>1.43565</td>\n",
       "      <td>5.16259</td>\n",
       "      <td>706.347</td>\n",
       "      <td>83.3811</td>\n",
       "      <td>28.713</td>\n",
       "      <td>37.9462</td>\n",
       "      <td>28.4489</td>\n",
       "      <td>22.1183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            instance_type compiled_batch_size  \\\n",
       "inf1_compiled_batch_size_2_compiled_cores_1   inf1.xlarge                   2   \n",
       "\n",
       "                                            user_batch_size accuracy  \\\n",
       "inf1_compiled_batch_size_2_compiled_cores_1              20    0.919   \n",
       "\n",
       "                                            prediction_time wall_time  \\\n",
       "inf1_compiled_batch_size_2_compiled_cores_1         1.43565   5.16259   \n",
       "\n",
       "                                            images_per_sec_mean  \\\n",
       "inf1_compiled_batch_size_2_compiled_cores_1             706.347   \n",
       "\n",
       "                                            images_per_sec_std latency_mean  \\\n",
       "inf1_compiled_batch_size_2_compiled_cores_1            83.3811       28.713   \n",
       "\n",
       "                                            latency_99th_percentile  \\\n",
       "inf1_compiled_batch_size_2_compiled_cores_1                 37.9462   \n",
       "\n",
       "                                            latency_median latency_min  \n",
       "inf1_compiled_batch_size_2_compiled_cores_1        28.4489     22.1183  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_1\n",
      "Running model resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_1, user_batch_size: 40\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "Images 120/1000. Average i/s 883.7303822460225\n",
      "Images 200/1000. Average i/s 910.3532189125489\n",
      "Images 320/1000. Average i/s 933.2543736882609\n",
      "Images 400/1000. Average i/s 928.786405079883\n",
      "Images 520/1000. Average i/s 925.2014730162482\n",
      "Images 600/1000. Average i/s 920.1611134377117\n",
      "Images 720/1000. Average i/s 914.1053154598816\n",
      "Images 800/1000. Average i/s 920.8408044158014\n",
      "Images 920/1000. Average i/s 924.3409428725789\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>compiled_batch_size</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf1_compiled_batch_size_4_compiled_cores_1</th>\n",
       "      <td>inf1.xlarge</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>0.918</td>\n",
       "      <td>1.08515</td>\n",
       "      <td>5.32341</td>\n",
       "      <td>928.432</td>\n",
       "      <td>77.482</td>\n",
       "      <td>43.4062</td>\n",
       "      <td>53.0889</td>\n",
       "      <td>43.2355</td>\n",
       "      <td>37.8447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            instance_type compiled_batch_size  \\\n",
       "inf1_compiled_batch_size_4_compiled_cores_1   inf1.xlarge                   4   \n",
       "\n",
       "                                            user_batch_size accuracy  \\\n",
       "inf1_compiled_batch_size_4_compiled_cores_1              40    0.918   \n",
       "\n",
       "                                            prediction_time wall_time  \\\n",
       "inf1_compiled_batch_size_4_compiled_cores_1         1.08515   5.32341   \n",
       "\n",
       "                                            images_per_sec_mean  \\\n",
       "inf1_compiled_batch_size_4_compiled_cores_1             928.432   \n",
       "\n",
       "                                            images_per_sec_std latency_mean  \\\n",
       "inf1_compiled_batch_size_4_compiled_cores_1             77.482      43.4062   \n",
       "\n",
       "                                            latency_99th_percentile  \\\n",
       "inf1_compiled_batch_size_4_compiled_cores_1                 53.0889   \n",
       "\n",
       "                                            latency_median latency_min  \n",
       "inf1_compiled_batch_size_4_compiled_cores_1        43.2355     37.8447  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: resnet50_inf1_saved_models/resnet50_batch_8_inf1_cores_1\n",
      "Running model resnet50_inf1_saved_models/resnet50_batch_8_inf1_cores_1, user_batch_size: 80\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "Images 160/1000. Average i/s 937.7894292926667\n",
      "Images 240/1000. Average i/s 923.1739342726929\n",
      "Images 320/1000. Average i/s 944.8058263792731\n",
      "Images 400/1000. Average i/s 952.043050016161\n",
      "Images 560/1000. Average i/s 952.4978564888605\n",
      "Images 640/1000. Average i/s 963.4370381307876\n",
      "Images 720/1000. Average i/s 972.7529568902988\n",
      "Images 800/1000. Average i/s 977.567721602059\n",
      "Images 960/1000. Average i/s 1026.6204212784692\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>compiled_batch_size</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf1_compiled_batch_size_8_compiled_cores_1</th>\n",
       "      <td>inf1.xlarge</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>0.919</td>\n",
       "      <td>1.03814</td>\n",
       "      <td>6.26644</td>\n",
       "      <td>1026.62</td>\n",
       "      <td>197.527</td>\n",
       "      <td>79.8568</td>\n",
       "      <td>90.9786</td>\n",
       "      <td>80.9529</td>\n",
       "      <td>48.6259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            instance_type compiled_batch_size  \\\n",
       "inf1_compiled_batch_size_8_compiled_cores_1   inf1.xlarge                   8   \n",
       "\n",
       "                                            user_batch_size accuracy  \\\n",
       "inf1_compiled_batch_size_8_compiled_cores_1              80    0.919   \n",
       "\n",
       "                                            prediction_time wall_time  \\\n",
       "inf1_compiled_batch_size_8_compiled_cores_1         1.03814   6.26644   \n",
       "\n",
       "                                            images_per_sec_mean  \\\n",
       "inf1_compiled_batch_size_8_compiled_cores_1             1026.62   \n",
       "\n",
       "                                            images_per_sec_std latency_mean  \\\n",
       "inf1_compiled_batch_size_8_compiled_cores_1            197.527      79.8568   \n",
       "\n",
       "                                            latency_99th_percentile  \\\n",
       "inf1_compiled_batch_size_8_compiled_cores_1                 90.9786   \n",
       "\n",
       "                                            latency_median latency_min  \n",
       "inf1_compiled_batch_size_8_compiled_cores_1        80.9529     48.6259  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: resnet50_inf1_saved_models/resnet50_batch_16_inf1_cores_1\n",
      "Running model resnet50_inf1_saved_models/resnet50_batch_16_inf1_cores_1, user_batch_size: 160\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "Images 160/1000. Average i/s 943.6387946463141\n",
      "Images 320/1000. Average i/s 972.5409722188607\n",
      "Images 480/1000. Average i/s 976.545997911181\n",
      "Images 640/1000. Average i/s 992.420051915203\n",
      "Images 800/1000. Average i/s 970.247370474821\n",
      "Images 960/1000. Average i/s 1183.9930141441357\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>compiled_batch_size</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf1_compiled_batch_size_16_compiled_cores_1</th>\n",
       "      <td>inf1.xlarge</td>\n",
       "      <td>16</td>\n",
       "      <td>160</td>\n",
       "      <td>0.919</td>\n",
       "      <td>1.0598</td>\n",
       "      <td>8.34057</td>\n",
       "      <td>1183.99</td>\n",
       "      <td>569.93</td>\n",
       "      <td>151.4</td>\n",
       "      <td>179.112</td>\n",
       "      <td>160.969</td>\n",
       "      <td>64.8701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             instance_type  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_1   inf1.xlarge   \n",
       "\n",
       "                                             compiled_batch_size  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_1                  16   \n",
       "\n",
       "                                             user_batch_size accuracy  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_1             160    0.919   \n",
       "\n",
       "                                             prediction_time wall_time  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_1          1.0598   8.34057   \n",
       "\n",
       "                                             images_per_sec_mean  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_1             1183.99   \n",
       "\n",
       "                                             images_per_sec_std latency_mean  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_1             569.93        151.4   \n",
       "\n",
       "                                             latency_99th_percentile  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_1                 179.112   \n",
       "\n",
       "                                             latency_median latency_min  \n",
       "inf1_compiled_batch_size_16_compiled_cores_1        160.969     64.8701  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: resnet50_inf1_saved_models/resnet50_batch_32_inf1_cores_1\n",
      "Running model resnet50_inf1_saved_models/resnet50_batch_32_inf1_cores_1, user_batch_size: 320\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "Images 320/1000. Average i/s 888.852374914444\n",
      "Images 640/1000. Average i/s 899.141056506683\n",
      "Images 960/1000. Average i/s 1347.1614323732751\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>compiled_batch_size</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf1_compiled_batch_size_32_compiled_cores_1</th>\n",
       "      <td>inf1.xlarge</td>\n",
       "      <td>32</td>\n",
       "      <td>320</td>\n",
       "      <td>0.918</td>\n",
       "      <td>1.18688</td>\n",
       "      <td>11.2203</td>\n",
       "      <td>1347.16</td>\n",
       "      <td>896.165</td>\n",
       "      <td>296.721</td>\n",
       "      <td>358.339</td>\n",
       "      <td>353.136</td>\n",
       "      <td>118.905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             instance_type  \\\n",
       "inf1_compiled_batch_size_32_compiled_cores_1   inf1.xlarge   \n",
       "\n",
       "                                             compiled_batch_size  \\\n",
       "inf1_compiled_batch_size_32_compiled_cores_1                  32   \n",
       "\n",
       "                                             user_batch_size accuracy  \\\n",
       "inf1_compiled_batch_size_32_compiled_cores_1             320    0.918   \n",
       "\n",
       "                                             prediction_time wall_time  \\\n",
       "inf1_compiled_batch_size_32_compiled_cores_1         1.18688   11.2203   \n",
       "\n",
       "                                             images_per_sec_mean  \\\n",
       "inf1_compiled_batch_size_32_compiled_cores_1             1347.16   \n",
       "\n",
       "                                             images_per_sec_std latency_mean  \\\n",
       "inf1_compiled_batch_size_32_compiled_cores_1            896.165      296.721   \n",
       "\n",
       "                                             latency_99th_percentile  \\\n",
       "inf1_compiled_batch_size_32_compiled_cores_1                 358.339   \n",
       "\n",
       "                                             latency_median latency_min  \n",
       "inf1_compiled_batch_size_32_compiled_cores_1        353.136     118.905  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: resnet50_inf1_saved_models/resnet50_batch_64_inf1_cores_1\n",
      "Running model resnet50_inf1_saved_models/resnet50_batch_64_inf1_cores_1, user_batch_size: 640\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "Images 640/1000. Average i/s 595.7175019689877\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>compiled_batch_size</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf1_compiled_batch_size_64_compiled_cores_1</th>\n",
       "      <td>inf1.xlarge</td>\n",
       "      <td>64</td>\n",
       "      <td>640</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.27574</td>\n",
       "      <td>21.2163</td>\n",
       "      <td>595.718</td>\n",
       "      <td>199.072</td>\n",
       "      <td>1137.87</td>\n",
       "      <td>868.995</td>\n",
       "      <td>1137.87</td>\n",
       "      <td>868.995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             instance_type  \\\n",
       "inf1_compiled_batch_size_64_compiled_cores_1   inf1.xlarge   \n",
       "\n",
       "                                             compiled_batch_size  \\\n",
       "inf1_compiled_batch_size_64_compiled_cores_1                  64   \n",
       "\n",
       "                                             user_batch_size accuracy  \\\n",
       "inf1_compiled_batch_size_64_compiled_cores_1             640     0.92   \n",
       "\n",
       "                                             prediction_time wall_time  \\\n",
       "inf1_compiled_batch_size_64_compiled_cores_1         2.27574   21.2163   \n",
       "\n",
       "                                             images_per_sec_mean  \\\n",
       "inf1_compiled_batch_size_64_compiled_cores_1             595.718   \n",
       "\n",
       "                                             images_per_sec_std latency_mean  \\\n",
       "inf1_compiled_batch_size_64_compiled_cores_1            199.072      1137.87   \n",
       "\n",
       "                                             latency_99th_percentile  \\\n",
       "inf1_compiled_batch_size_64_compiled_cores_1                 868.995   \n",
       "\n",
       "                                             latency_median latency_min  \n",
       "inf1_compiled_batch_size_64_compiled_cores_1        1137.87     868.995  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inf1_compiled_batch_size_1_compiled_cores_1</th>\n",
       "      <th>inf1_compiled_batch_size_2_compiled_cores_1</th>\n",
       "      <th>inf1_compiled_batch_size_4_compiled_cores_1</th>\n",
       "      <th>inf1_compiled_batch_size_8_compiled_cores_1</th>\n",
       "      <th>inf1_compiled_batch_size_16_compiled_cores_1</th>\n",
       "      <th>inf1_compiled_batch_size_32_compiled_cores_1</th>\n",
       "      <th>inf1_compiled_batch_size_64_compiled_cores_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>instance_type</th>\n",
       "      <td>inf1.xlarge</td>\n",
       "      <td>inf1.xlarge</td>\n",
       "      <td>inf1.xlarge</td>\n",
       "      <td>inf1.xlarge</td>\n",
       "      <td>inf1.xlarge</td>\n",
       "      <td>inf1.xlarge</td>\n",
       "      <td>inf1.xlarge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compiled_batch_size</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_batch_size</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>320</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.919</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_time</th>\n",
       "      <td>2.20407</td>\n",
       "      <td>1.43565</td>\n",
       "      <td>1.08515</td>\n",
       "      <td>1.03814</td>\n",
       "      <td>1.0598</td>\n",
       "      <td>1.18688</td>\n",
       "      <td>2.27574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wall_time</th>\n",
       "      <td>5.14522</td>\n",
       "      <td>5.16259</td>\n",
       "      <td>5.32341</td>\n",
       "      <td>6.26644</td>\n",
       "      <td>8.34057</td>\n",
       "      <td>11.2203</td>\n",
       "      <td>21.2163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <td>464.954</td>\n",
       "      <td>706.347</td>\n",
       "      <td>928.432</td>\n",
       "      <td>1026.62</td>\n",
       "      <td>1183.99</td>\n",
       "      <td>1347.16</td>\n",
       "      <td>595.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <td>72.2145</td>\n",
       "      <td>83.3811</td>\n",
       "      <td>77.482</td>\n",
       "      <td>197.527</td>\n",
       "      <td>569.93</td>\n",
       "      <td>896.165</td>\n",
       "      <td>199.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_mean</th>\n",
       "      <td>22.0407</td>\n",
       "      <td>28.713</td>\n",
       "      <td>43.4062</td>\n",
       "      <td>79.8568</td>\n",
       "      <td>151.4</td>\n",
       "      <td>296.721</td>\n",
       "      <td>1137.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <td>30.8819</td>\n",
       "      <td>37.9462</td>\n",
       "      <td>53.0889</td>\n",
       "      <td>90.9786</td>\n",
       "      <td>179.112</td>\n",
       "      <td>358.339</td>\n",
       "      <td>868.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_median</th>\n",
       "      <td>21.4716</td>\n",
       "      <td>28.4489</td>\n",
       "      <td>43.2355</td>\n",
       "      <td>80.9529</td>\n",
       "      <td>160.969</td>\n",
       "      <td>353.136</td>\n",
       "      <td>1137.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_min</th>\n",
       "      <td>15.3298</td>\n",
       "      <td>22.1183</td>\n",
       "      <td>37.8447</td>\n",
       "      <td>48.6259</td>\n",
       "      <td>64.8701</td>\n",
       "      <td>118.905</td>\n",
       "      <td>868.995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        inf1_compiled_batch_size_1_compiled_cores_1  \\\n",
       "instance_type                                           inf1.xlarge   \n",
       "compiled_batch_size                                               1   \n",
       "user_batch_size                                                  10   \n",
       "accuracy                                                      0.919   \n",
       "prediction_time                                             2.20407   \n",
       "wall_time                                                   5.14522   \n",
       "images_per_sec_mean                                         464.954   \n",
       "images_per_sec_std                                          72.2145   \n",
       "latency_mean                                                22.0407   \n",
       "latency_99th_percentile                                     30.8819   \n",
       "latency_median                                              21.4716   \n",
       "latency_min                                                 15.3298   \n",
       "\n",
       "                        inf1_compiled_batch_size_2_compiled_cores_1  \\\n",
       "instance_type                                           inf1.xlarge   \n",
       "compiled_batch_size                                               2   \n",
       "user_batch_size                                                  20   \n",
       "accuracy                                                      0.919   \n",
       "prediction_time                                             1.43565   \n",
       "wall_time                                                   5.16259   \n",
       "images_per_sec_mean                                         706.347   \n",
       "images_per_sec_std                                          83.3811   \n",
       "latency_mean                                                 28.713   \n",
       "latency_99th_percentile                                     37.9462   \n",
       "latency_median                                              28.4489   \n",
       "latency_min                                                 22.1183   \n",
       "\n",
       "                        inf1_compiled_batch_size_4_compiled_cores_1  \\\n",
       "instance_type                                           inf1.xlarge   \n",
       "compiled_batch_size                                               4   \n",
       "user_batch_size                                                  40   \n",
       "accuracy                                                      0.918   \n",
       "prediction_time                                             1.08515   \n",
       "wall_time                                                   5.32341   \n",
       "images_per_sec_mean                                         928.432   \n",
       "images_per_sec_std                                           77.482   \n",
       "latency_mean                                                43.4062   \n",
       "latency_99th_percentile                                     53.0889   \n",
       "latency_median                                              43.2355   \n",
       "latency_min                                                 37.8447   \n",
       "\n",
       "                        inf1_compiled_batch_size_8_compiled_cores_1  \\\n",
       "instance_type                                           inf1.xlarge   \n",
       "compiled_batch_size                                               8   \n",
       "user_batch_size                                                  80   \n",
       "accuracy                                                      0.919   \n",
       "prediction_time                                             1.03814   \n",
       "wall_time                                                   6.26644   \n",
       "images_per_sec_mean                                         1026.62   \n",
       "images_per_sec_std                                          197.527   \n",
       "latency_mean                                                79.8568   \n",
       "latency_99th_percentile                                     90.9786   \n",
       "latency_median                                              80.9529   \n",
       "latency_min                                                 48.6259   \n",
       "\n",
       "                        inf1_compiled_batch_size_16_compiled_cores_1  \\\n",
       "instance_type                                            inf1.xlarge   \n",
       "compiled_batch_size                                               16   \n",
       "user_batch_size                                                  160   \n",
       "accuracy                                                       0.919   \n",
       "prediction_time                                               1.0598   \n",
       "wall_time                                                    8.34057   \n",
       "images_per_sec_mean                                          1183.99   \n",
       "images_per_sec_std                                            569.93   \n",
       "latency_mean                                                   151.4   \n",
       "latency_99th_percentile                                      179.112   \n",
       "latency_median                                               160.969   \n",
       "latency_min                                                  64.8701   \n",
       "\n",
       "                        inf1_compiled_batch_size_32_compiled_cores_1  \\\n",
       "instance_type                                            inf1.xlarge   \n",
       "compiled_batch_size                                               32   \n",
       "user_batch_size                                                  320   \n",
       "accuracy                                                       0.918   \n",
       "prediction_time                                              1.18688   \n",
       "wall_time                                                    11.2203   \n",
       "images_per_sec_mean                                          1347.16   \n",
       "images_per_sec_std                                           896.165   \n",
       "latency_mean                                                 296.721   \n",
       "latency_99th_percentile                                      358.339   \n",
       "latency_median                                               353.136   \n",
       "latency_min                                                  118.905   \n",
       "\n",
       "                        inf1_compiled_batch_size_64_compiled_cores_1  \n",
       "instance_type                                            inf1.xlarge  \n",
       "compiled_batch_size                                               64  \n",
       "user_batch_size                                                  640  \n",
       "accuracy                                                        0.92  \n",
       "prediction_time                                              2.27574  \n",
       "wall_time                                                    21.2163  \n",
       "images_per_sec_mean                                          595.718  \n",
       "images_per_sec_std                                           199.072  \n",
       "latency_mean                                                 1137.87  \n",
       "latency_99th_percentile                                      868.995  \n",
       "latency_median                                               1137.87  \n",
       "latency_min                                                  868.995  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inf1_model_dir = 'resnet50_inf1_saved_models'\n",
    "\n",
    "compile_options = [{'batch_size': 1, 'num_cores': 1},\n",
    "                  {'batch_size': 2, 'num_cores': 1},\n",
    "                  {'batch_size': 4, 'num_cores': 1},\n",
    "                  {'batch_size': 8, 'num_cores': 1},\n",
    "                  {'batch_size': 16, 'num_cores': 1},\n",
    "                  {'batch_size': 32, 'num_cores': 1},\n",
    "                  {'batch_size': 64, 'num_cores': 1}]\n",
    "\n",
    "iter_ds = pd.DataFrame()\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for opt in compile_options:\n",
    "    batch_size = opt[\"batch_size\"]\n",
    "    num_cores = opt[\"num_cores\"]\n",
    "    compiled_model_dir = f'resnet50_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "    inf1_compiled_model_dir = os.path.join(inf1_model_dir, compiled_model_dir)\n",
    "   \n",
    "    print(f'inf1_compiled_model_dir: {inf1_compiled_model_dir}')\n",
    "    col_name = lambda opt: f'inf1_{batch_size}_multicores_{num_cores}'\n",
    "    \n",
    "    res, iter_times = inf1_predict_benchmark_single_threaded(inf1_compiled_model_dir,\n",
    "                                                                     batch_size = batch_size,\n",
    "                                                                     user_batch_size = batch_size*10,\n",
    "                                                                     num_cores = num_cores,\n",
    "                                                                     use_cache=False, \n",
    "                                                                     warm_up=10)\n",
    "    \n",
    "    iter_ds = pd.concat([iter_ds, pd.DataFrame(iter_times, columns=[col_name(opt)])], axis=1)\n",
    "    results = pd.concat([results, res], axis=1)\n",
    "    \n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core size: 1 compile start\n",
      "-----------batch size: 1, num cores: 1----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph {subgraph neuron_op_d6f098c01c780733 with input tensors [\"<tf.Tensor 'input_10/_0:0' shape=(1, 224, 224, 3) dtype=float32>\"], output tensors [\"<tf.Tensor 'probs/Softmax:0' shape=(1, 1000) dtype=float32>\"]} with neuron-cc; you may check progress by inspecting file /home/ubuntu/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4647\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 876\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 874\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_1/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_1\n",
      "Compile time: 72.27322387695312\n",
      "resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_1\n",
      "{'OnNeuronRatio': 0.997716894977169}\n",
      "----------- Done! ----------- \n",
      "\n",
      "core size: 2 compile start\n",
      "-----------batch size: 1, num cores: 2----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph {subgraph neuron_op_d6f098c01c780733 with input tensors [\"<tf.Tensor 'input_10/_0:0' shape=(1, 224, 224, 3) dtype=float32>\"], output tensors [\"<tf.Tensor 'probs/Softmax:0' shape=(1, 1000) dtype=float32>\"]} with neuron-cc; you may check progress by inspecting file /home/ubuntu/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_2/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4647\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 876\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 874\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_2/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_2\n",
      "Compile time: 77.5646812915802\n",
      "resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_2\n",
      "{'OnNeuronRatio': 0.997716894977169}\n",
      "----------- Done! ----------- \n",
      "\n",
      "core size: 3 compile start\n",
      "-----------batch size: 1, num cores: 3----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph {subgraph neuron_op_d6f098c01c780733 with input tensors [\"<tf.Tensor 'input_10/_0:0' shape=(1, 224, 224, 3) dtype=float32>\"], output tensors [\"<tf.Tensor 'probs/Softmax:0' shape=(1, 1000) dtype=float32>\"]} with neuron-cc; you may check progress by inspecting file /home/ubuntu/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_3/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4647\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 876\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 874\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_3/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_3\n",
      "Compile time: 76.56462621688843\n",
      "resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_3\n",
      "{'OnNeuronRatio': 0.997716894977169}\n",
      "----------- Done! ----------- \n",
      "\n",
      "core size: 4 compile start\n",
      "-----------batch size: 1, num cores: 4----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph {subgraph neuron_op_d6f098c01c780733 with input tensors [\"<tf.Tensor 'input_10/_0:0' shape=(1, 224, 224, 3) dtype=float32>\"], output tensors [\"<tf.Tensor 'probs/Softmax:0' shape=(1, 1000) dtype=float32>\"]} with neuron-cc; you may check progress by inspecting file /home/ubuntu/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_4/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4647\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 876\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 874\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_4/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_4\n",
      "Compile time: 86.02925252914429\n",
      "resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_4\n",
      "{'OnNeuronRatio': 0.997716894977169}\n",
      "----------- Done! ----------- \n",
      "\n",
      "core size: 5 compile start\n",
      "-----------batch size: 1, num cores: 5----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph {subgraph neuron_op_d6f098c01c780733 with input tensors [\"<tf.Tensor 'input_10/_0:0' shape=(1, 224, 224, 3) dtype=float32>\"], output tensors [\"<tf.Tensor 'probs/Softmax:0' shape=(1, 1000) dtype=float32>\"]} with neuron-cc; you may check progress by inspecting file /home/ubuntu/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_5/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4647\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 876\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 874\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_5/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_5\n",
      "Compile time: 89.83143544197083\n",
      "resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_5\n",
      "{'OnNeuronRatio': 0.997716894977169}\n",
      "----------- Done! ----------- \n",
      "\n",
      "core size: 6 compile start\n",
      "-----------batch size: 1, num cores: 6----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph {subgraph neuron_op_d6f098c01c780733 with input tensors [\"<tf.Tensor 'input_10/_0:0' shape=(1, 224, 224, 3) dtype=float32>\"], output tensors [\"<tf.Tensor 'probs/Softmax:0' shape=(1, 1000) dtype=float32>\"]} with neuron-cc; you may check progress by inspecting file /home/ubuntu/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_6/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4647\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 876\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 874\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_6/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_6\n",
      "Compile time: 94.06639623641968\n",
      "resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_6\n",
      "{'OnNeuronRatio': 0.997716894977169}\n",
      "----------- Done! ----------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inf1_model_dir = 'resnet50_inf1_saved_models'\n",
    "saved_model_dir = 'resnet50_saved_model'\n",
    "\n",
    "\n",
    "# testing batch size\n",
    "core_list = [1,2,3,4,5,6]\n",
    "for core in core_list:\n",
    "    print('core size:', core, 'compile start')\n",
    "    compile_inf1_model(saved_model_dir, inf1_model_dir, batch_size=1, num_cores=core)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_1\n",
      "Running model resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_1, user_batch_size: 10\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "Images 100/1000. Average i/s 492.7609983197934\n",
      "Images 200/1000. Average i/s 498.76356187020656\n",
      "Images 300/1000. Average i/s 487.3440884835897\n",
      "Images 400/1000. Average i/s 496.515840915395\n",
      "Images 500/1000. Average i/s 494.38088381082173\n",
      "Images 600/1000. Average i/s 492.91520717919605\n",
      "Images 700/1000. Average i/s 492.3006276132294\n",
      "Images 800/1000. Average i/s 489.16447506571853\n",
      "Images 900/1000. Average i/s 486.91232490944327\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>compiled_batch_size</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf1_compiled_batch_size_1_compiled_cores_1</th>\n",
       "      <td>inf1.xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.919</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>5.25748</td>\n",
       "      <td>483.723</td>\n",
       "      <td>80.6067</td>\n",
       "      <td>21.282</td>\n",
       "      <td>31.4922</td>\n",
       "      <td>20.7072</td>\n",
       "      <td>14.9789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            instance_type compiled_batch_size  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_1   inf1.xlarge                   1   \n",
       "\n",
       "                                            user_batch_size accuracy  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_1              10    0.919   \n",
       "\n",
       "                                            prediction_time wall_time  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_1          2.1282   5.25748   \n",
       "\n",
       "                                            images_per_sec_mean  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_1             483.723   \n",
       "\n",
       "                                            images_per_sec_std latency_mean  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_1            80.6067       21.282   \n",
       "\n",
       "                                            latency_99th_percentile  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_1                 31.4922   \n",
       "\n",
       "                                            latency_median latency_min  \n",
       "inf1_compiled_batch_size_1_compiled_cores_1        20.7072     14.9789  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_2\n",
      "Running model resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_2, user_batch_size: 10\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "Images 100/1000. Average i/s 358.794640450612\n",
      "Images 200/1000. Average i/s 356.2934837527057\n",
      "Images 300/1000. Average i/s 360.7169010822598\n",
      "Images 400/1000. Average i/s 361.79747439280237\n",
      "Images 500/1000. Average i/s 360.86751193207414\n",
      "Images 600/1000. Average i/s 360.79159999749197\n",
      "Images 700/1000. Average i/s 360.03486045583173\n",
      "Images 800/1000. Average i/s 360.59974105959327\n",
      "Images 900/1000. Average i/s 361.2857916367616\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>compiled_batch_size</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf1_compiled_batch_size_1_compiled_cores_2</th>\n",
       "      <td>inf1.xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.917</td>\n",
       "      <td>2.78887</td>\n",
       "      <td>4.35097</td>\n",
       "      <td>362.019</td>\n",
       "      <td>34.8972</td>\n",
       "      <td>27.8887</td>\n",
       "      <td>35.2595</td>\n",
       "      <td>27.1313</td>\n",
       "      <td>23.3169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            instance_type compiled_batch_size  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_2   inf1.xlarge                   1   \n",
       "\n",
       "                                            user_batch_size accuracy  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_2              10    0.917   \n",
       "\n",
       "                                            prediction_time wall_time  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_2         2.78887   4.35097   \n",
       "\n",
       "                                            images_per_sec_mean  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_2             362.019   \n",
       "\n",
       "                                            images_per_sec_std latency_mean  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_2            34.8972      27.8887   \n",
       "\n",
       "                                            latency_99th_percentile  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_2                 35.2595   \n",
       "\n",
       "                                            latency_median latency_min  \n",
       "inf1_compiled_batch_size_1_compiled_cores_2        27.1313     23.3169  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_3\n",
      "Running model resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_3, user_batch_size: 10\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "Images 100/1000. Average i/s 355.1456372772402\n",
      "Images 200/1000. Average i/s 354.43537802814114\n",
      "Images 300/1000. Average i/s 349.504273352511\n",
      "Images 400/1000. Average i/s 352.42197405317285\n",
      "Images 500/1000. Average i/s 356.0861528630035\n",
      "Images 600/1000. Average i/s 357.661102360892\n",
      "Images 700/1000. Average i/s 358.6916404156829\n",
      "Images 800/1000. Average i/s 359.2757587603078\n",
      "Images 900/1000. Average i/s 359.2126386948329\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>compiled_batch_size</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf1_compiled_batch_size_1_compiled_cores_3</th>\n",
       "      <td>inf1.xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.918</td>\n",
       "      <td>2.79387</td>\n",
       "      <td>4.45548</td>\n",
       "      <td>361.733</td>\n",
       "      <td>37.0595</td>\n",
       "      <td>27.9387</td>\n",
       "      <td>34.0264</td>\n",
       "      <td>27.724</td>\n",
       "      <td>23.0267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            instance_type compiled_batch_size  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_3   inf1.xlarge                   1   \n",
       "\n",
       "                                            user_batch_size accuracy  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_3              10    0.918   \n",
       "\n",
       "                                            prediction_time wall_time  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_3         2.79387   4.45548   \n",
       "\n",
       "                                            images_per_sec_mean  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_3             361.733   \n",
       "\n",
       "                                            images_per_sec_std latency_mean  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_3            37.0595      27.9387   \n",
       "\n",
       "                                            latency_99th_percentile  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_3                 34.0264   \n",
       "\n",
       "                                            latency_median latency_min  \n",
       "inf1_compiled_batch_size_1_compiled_cores_3         27.724     23.0267  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_4\n",
      "Running model resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_4, user_batch_size: 10\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "Images 100/1000. Average i/s 359.47809851203147\n",
      "Images 200/1000. Average i/s 368.8593927009845\n",
      "Images 300/1000. Average i/s 369.3689269676493\n",
      "Images 400/1000. Average i/s 375.1979932692287\n",
      "Images 500/1000. Average i/s 374.63680974376683\n",
      "Images 600/1000. Average i/s 373.7329000241914\n",
      "Images 700/1000. Average i/s 370.0372652478046\n",
      "Images 800/1000. Average i/s 369.3100084144382\n",
      "Images 900/1000. Average i/s 369.6149914304928\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>compiled_batch_size</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf1_compiled_batch_size_1_compiled_cores_4</th>\n",
       "      <td>inf1.xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.916</td>\n",
       "      <td>2.71946</td>\n",
       "      <td>4.3811</td>\n",
       "      <td>372.488</td>\n",
       "      <td>41.9521</td>\n",
       "      <td>27.1946</td>\n",
       "      <td>34.7743</td>\n",
       "      <td>26.9332</td>\n",
       "      <td>21.4508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            instance_type compiled_batch_size  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_4   inf1.xlarge                   1   \n",
       "\n",
       "                                            user_batch_size accuracy  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_4              10    0.916   \n",
       "\n",
       "                                            prediction_time wall_time  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_4         2.71946    4.3811   \n",
       "\n",
       "                                            images_per_sec_mean  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_4             372.488   \n",
       "\n",
       "                                            images_per_sec_std latency_mean  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_4            41.9521      27.1946   \n",
       "\n",
       "                                            latency_99th_percentile  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_4                 34.7743   \n",
       "\n",
       "                                            latency_median latency_min  \n",
       "inf1_compiled_batch_size_1_compiled_cores_4        26.9332     21.4508  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_5\n",
      "Running model resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_5, user_batch_size: 10\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "2 root error(s) found.\n  (0) Internal: nrt::load failed with grpc status code 0, error message \"\"; nrt status code 9, details \"[NMGR:kmgr_load_nn_from_neff] Insufficient number of VNCs: 4, required: 5\n[NMGR:kmgr_load_nn] Failed to load NN: 1.4.1.0+737cbb69a-/home/ubuntu/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_5/neuron_op_d6f098c01c780733, err: 9\n[NRTD:load] DLR model load failed\n\"\n\t [[node conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp/neuron_op_d6f098c01c780733 (defined at /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n  (1) Internal: nrt::load failed with grpc status code 0, error message \"\"; nrt status code 9, details \"[NMGR:kmgr_load_nn_from_neff] Insufficient number of VNCs: 4, required: 5\n[NMGR:kmgr_load_nn] Failed to load NN: 1.4.1.0+737cbb69a-/home/ubuntu/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_5/neuron_op_d6f098c01c780733, err: 9\n[NRTD:load] DLR model load failed\n\"\n\t [[node conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp/neuron_op_d6f098c01c780733 (defined at /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\t [[conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp/neuron_op_d6f098c01c780733/_3]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp/neuron_op_d6f098c01c780733':\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 619, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n    return callable(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n    return callable(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n    return callable(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 538, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n    return callable(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-6c5ac3661dcf>\", line 27, in <module>\n    warm_up=10)\n  File \"<ipython-input-13-b3806d957b95>\", line 4, in inf1_predict_benchmark_single_threaded\n    model_inf1 = tf.contrib.predictor.from_saved_model(neuron_saved_model_name)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/predictor/predictor_factories.py\", line 153, in from_saved_model\n    config=config)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/predictor/saved_model_predictor.py\", line 153, in __init__\n    loader.load(self._session, tags.split(','), export_dir)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/loader_impl.py\", line 269, in load\n    return loader.load(sess, tags, import_scope, **saver_kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/loader_impl.py\", line 422, in load\n    **saver_kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/loader_impl.py\", line 352, in load_graph\n    meta_graph_def, import_scope=import_scope, **saver_kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py\", line 1477, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/meta_graph.py\", line 809, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 405, in import_graph_def\n    producer_op_list=producer_op_list)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 517, in _import_graph_def_internal\n    _ProcessNewOps(graph)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 243, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3561, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3561, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3451, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: 2 root error(s) found.\n  (0) Internal: nrt::load failed with grpc status code 0, error message \"\"; nrt status code 9, details \"[NMGR:kmgr_load_nn_from_neff] Insufficient number of VNCs: 4, required: 5\n[NMGR:kmgr_load_nn] Failed to load NN: 1.4.1.0+737cbb69a-/home/ubuntu/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_5/neuron_op_d6f098c01c780733, err: 9\n[NRTD:load] DLR model load failed\n\"\n\t [[{{node conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp/neuron_op_d6f098c01c780733}}]]\n  (1) Internal: nrt::load failed with grpc status code 0, error message \"\"; nrt status code 9, details \"[NMGR:kmgr_load_nn_from_neff] Insufficient number of VNCs: 4, required: 5\n[NMGR:kmgr_load_nn] Failed to load NN: 1.4.1.0+737cbb69a-/home/ubuntu/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_5/neuron_op_d6f098c01c780733, err: 9\n[NRTD:load] DLR model load failed\n\"\n\t [[{{node conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp/neuron_op_d6f098c01c780733}}]]\n\t [[conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp/neuron_op_d6f098c01c780733/_3]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6c5ac3661dcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                                                      \u001b[0mnum_cores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_cores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                                                                      \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                                                                      warm_up=10)\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0miter_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miter_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-b3806d957b95>\u001b[0m in \u001b[0;36minf1_predict_benchmark_single_threaded\u001b[0;34m(neuron_saved_model_name, batch_size, user_batch_size, num_cores, use_cache, warm_up)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarm_up\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_inf1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_feed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/predictor/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_dict)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: 2 root error(s) found.\n  (0) Internal: nrt::load failed with grpc status code 0, error message \"\"; nrt status code 9, details \"[NMGR:kmgr_load_nn_from_neff] Insufficient number of VNCs: 4, required: 5\n[NMGR:kmgr_load_nn] Failed to load NN: 1.4.1.0+737cbb69a-/home/ubuntu/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_5/neuron_op_d6f098c01c780733, err: 9\n[NRTD:load] DLR model load failed\n\"\n\t [[node conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp/neuron_op_d6f098c01c780733 (defined at /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n  (1) Internal: nrt::load failed with grpc status code 0, error message \"\"; nrt status code 9, details \"[NMGR:kmgr_load_nn_from_neff] Insufficient number of VNCs: 4, required: 5\n[NMGR:kmgr_load_nn] Failed to load NN: 1.4.1.0+737cbb69a-/home/ubuntu/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_5/neuron_op_d6f098c01c780733, err: 9\n[NRTD:load] DLR model load failed\n\"\n\t [[node conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp/neuron_op_d6f098c01c780733 (defined at /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\t [[conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp/neuron_op_d6f098c01c780733/_3]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp/neuron_op_d6f098c01c780733':\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 619, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n    return callable(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n    return callable(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n    return callable(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 538, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n    return callable(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-6c5ac3661dcf>\", line 27, in <module>\n    warm_up=10)\n  File \"<ipython-input-13-b3806d957b95>\", line 4, in inf1_predict_benchmark_single_threaded\n    model_inf1 = tf.contrib.predictor.from_saved_model(neuron_saved_model_name)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/predictor/predictor_factories.py\", line 153, in from_saved_model\n    config=config)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/predictor/saved_model_predictor.py\", line 153, in __init__\n    loader.load(self._session, tags.split(','), export_dir)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/loader_impl.py\", line 269, in load\n    return loader.load(sess, tags, import_scope, **saver_kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/loader_impl.py\", line 422, in load\n    **saver_kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/loader_impl.py\", line 352, in load_graph\n    meta_graph_def, import_scope=import_scope, **saver_kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py\", line 1477, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/meta_graph.py\", line 809, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 405, in import_graph_def\n    producer_op_list=producer_op_list)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 517, in _import_graph_def_internal\n    _ProcessNewOps(graph)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 243, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3561, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3561, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3451, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "inf1_model_dir = 'resnet50_inf1_saved_models'\n",
    "\n",
    "compile_options = [{'batch_size': 1, 'num_cores': 1},\n",
    "                  {'batch_size': 1, 'num_cores': 2},\n",
    "                  {'batch_size': 1, 'num_cores': 3},\n",
    "                  {'batch_size': 1, 'num_cores': 4},\n",
    "                  {'batch_size': 1, 'num_cores': 5},\n",
    "                  {'batch_size': 1, 'num_cores': 6}]\n",
    "\n",
    "iter_ds = pd.DataFrame()\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for opt in compile_options:\n",
    "    batch_size = opt[\"batch_size\"]\n",
    "    num_cores = opt[\"num_cores\"]\n",
    "    compiled_model_dir = f'resnet50_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "    inf1_compiled_model_dir = os.path.join(inf1_model_dir, compiled_model_dir)\n",
    "   \n",
    "    print(f'inf1_compiled_model_dir: {inf1_compiled_model_dir}')\n",
    "    col_name = lambda opt: f'inf1_{batch_size}_multicores_{num_cores}'\n",
    "    \n",
    "    res, iter_times = inf1_predict_benchmark_single_threaded(inf1_compiled_model_dir,\n",
    "                                                                     batch_size = batch_size,\n",
    "                                                                     user_batch_size = batch_size*10,\n",
    "                                                                     num_cores = num_cores,\n",
    "                                                                     use_cache=False, \n",
    "                                                                     warm_up=10)\n",
    "    \n",
    "    iter_ds = pd.concat([iter_ds, pd.DataFrame(iter_times, columns=[col_name(opt)])], axis=1)\n",
    "    results = pd.concat([results, res], axis=1)\n",
    "    \n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuron_tensorflow_p36",
   "language": "python",
   "name": "aws_neuron_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
